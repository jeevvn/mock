# üöë **TRIAGE-AI**

### *Trust-Weighted Risk Interpretation & Escalation*

---

### ‚ùì What problem does TRIAGE-AI solve?

**TRIAGE-AI** is a **safety-first medical decision-support system** built to answer one focused question:

> **‚ÄúHow urgently should this medical situation be reviewed?‚Äù**

Instead of diagnosing diseases or prescribing treatments, TRIAGE-AI focuses purely on **triage and escalation** ‚Äî deciding **when** attention is needed, not **what** the condition is.

---

## üß† Why TRIAGE-AI?

Medical data is often **fragmented and confusing**:

* üìä Lab values without context
* üíä Medications with hidden interactions
* üó£Ô∏è Vague or overlapping symptoms

This commonly results in:

* üö® **Unnecessary panic** and alert fatigue
* üò¥ **Dangerous delays** in identifying early risk

---

## üéØ Our Solution

TRIAGE-AI transforms scattered medical inputs into **one clear, explainable escalation decision**:

| Escalation Level | Meaning                       |
| ---------------- | ----------------------------- |
| üü¢ **LOW**       | Monitor                       |
| üü° **MEDIUM**    | Medical review advised        |
| üî¥ **HIGH**      | Seek urgent medical attention |

This keeps decisions **clear, calm, and actionable**.

---

## ‚ú® What Makes TRIAGE-AI Special

‚úÖ **Multi-agent reasoning** ‚Äî multiple risk perspectives
‚úÖ **Adaptive trust weighting** ‚Äî context-aware, not static
‚úÖ **Deterministic & explainable** ‚Äî no black-box decisions
‚úÖ **Safety-first design** ‚Äî no diagnosis, no treatment advice

> ‚ö†Ô∏è This is **decision support**, not decision replacement.

---

## üîÑ System Flow (High Level)

```
User Input
   ‚Üì
Medical Evidence Agents (facts only)
   ‚Üì
Perspective Agents (opinions)
   ‚Üì
Meta Agent (who to trust more?)
   ‚Üì
Arbitration (one escalation decision)
   ‚Üì
Explainability (plain-English output)
```

Each stage has **one responsibility**, making the system easy to:

* explain
* debug
* trust

---

## üß© Architecture Overview

### üîπ Level 0 ‚Äî Input

Collected information:

* Age, sex
* Current medications
* Selected lab values
* Patient-reported symptoms

‚û°Ô∏è Normalized into structured JSON
‚û°Ô∏è **No reasoning happens here**

---

### üîπ Level 1 ‚Äî Medical Evidence Agents

Objective signal extraction only:

* üß™ **Lab Analysis Agent**
* üíä **Medication Interaction Agent**
* ü©∫ **Symptom Correlation Agent**

‚ùó These agents **do not communicate**
‚ùó They **do not interpret or judge**

---

### üîπ Level 2 ‚Äî Perspective Agents

Independent risk viewpoints:

* üòä **Optimistic** ‚Äî assumes best reasonable case
* ‚öñÔ∏è **Analytical** ‚Äî balances evidence & uncertainty
* üö® **Pessimistic** ‚Äî prioritizes early risk detection

Each outputs:

* concern level *(low / medium / high)*
* confidence score
* rationale

---

### üîπ Level 3 ‚Äî Meta Agent

Acts as a **moderator**, not a doctor.

* Observes evidence severity
* Detects agreement vs disagreement
* Adjusts how much each perspective is trusted

‚û°Ô∏è Output: **adaptive trust weights**

---

### üîπ Level 4 ‚Äî Arbitration

The **only decision-maker**.

* Converts concern ‚Üí numeric scores
* Scales by confidence & trust
* Aggregates into one risk score
* Maps score ‚Üí **LOW / MEDIUM / HIGH**

‚ö†Ô∏è Includes **hard safety overrides** for critical lab values

---

### üîπ Level 5 ‚Äî Explainability

Produces:

* üó£Ô∏è Clear, human-readable reasoning
* üéØ Action-oriented recommendation
* üõ°Ô∏è Mandatory safety disclaimer

---

## üõ°Ô∏è Safety by Design

* No diagnosis or treatment advice
* Deterministic decision logic
* Critical-value overrides (e.g., extreme labs)
* Input sanity checks
* LLMs (if used) restricted to interpretation layers only

---

## üóÇÔ∏è Project Structure

```
TRIAGE-AI/
‚îÇ
‚îú‚îÄ‚îÄ app.py                  # Streamlit orchestration layer
‚îú‚îÄ‚îÄ explainability.py
‚îÇ
‚îú‚îÄ‚îÄ evidence/               # Level 1
‚îú‚îÄ‚îÄ perspectives/           # Level 2
‚îú‚îÄ‚îÄ meta/                   # Level 3
‚îú‚îÄ‚îÄ arbitration/            # Level 4
‚îÇ
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îî‚îÄ‚îÄ run_meta_pipeline.py
‚îÇ
‚îî‚îÄ‚îÄ README.md
```

---

## ‚ñ∂Ô∏è How to Run (Demo-Ready)

### 1Ô∏è‚É£ Install dependencies

```bash
pip install streamlit
```

### 2Ô∏è‚É£ Validate core logic (Levels 3‚Äì5)

```bash
python tests/run_meta_pipeline.py
```

### 3Ô∏è‚É£ Launch the application

```bash
streamlit run app.py
```

---

## üß™ Sample Output

```
Escalation Level: MEDIUM
Explanation: Some information is outside the normal range, but does not suggest an emergency.
Recommended Action: Medical review advised.
```

---

## üöÄ Use Cases

* üßë‚Äç‚öïÔ∏è Patient-facing triage assistance
* üè• Clinical prioritization support
* üíä Medication interaction awareness
* üì° Remote health monitoring
* üß™ Safe medical AI demonstrations

---

## üèÅ One-Line Pitch (Hackathon Ready)

> **TRIAGE-AI is a trust-weighted, multi-agent medical escalation system that safely determines urgency without diagnosing or treating.**

---

## ‚ö†Ô∏è Disclaimer

TRIAGE-AI does **not** provide medical advice, diagnosis, or treatment recommendations.
It is intended solely to support **escalation and prioritization decisions**.

